{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "%env OPENAI_API_KEY=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\n",
    "import openai\n",
    "import tiktoken"
   ],
   "id": "8ce767ca51223289",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(encoding.encode(text))"
   ],
   "id": "b8e2767f439d3442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pr√©parer le prompt pour guider ChatGPT\n",
    "\n",
    "def get_summary(transcription):\n",
    "    prompt = f\"\"\"\n",
    "        You are given a cleaned transcription of a day trading lesson from Ross Cameron.\n",
    "\n",
    "        Your task:\n",
    "        - Analyze the content carefully.\n",
    "        - Extract and organize the information into a structured and logical format, as if it were a formal study lesson.\n",
    "        - Summarize each main idea with a clear title and a short, precise explanation.\n",
    "        - Maintain all important technical points, trading strategies, and psychological advice.\n",
    "        - Avoid removing any critical information, but feel free to rephrase for clarity.\n",
    "        - Create a concise table of contents at the beginning of the document based on the lesson structure.\n",
    "\n",
    "        Output requirements:\n",
    "        - Start with a Table of Contents listing each main topic and subtopic.\n",
    "        - Then present the full organized lesson, divided into clear sections with headings and concise, professional explanations.\n",
    "\n",
    "        DO NOT invent or add information that was not in the original transcription.\n",
    "        DO NOT omit any essential advice, concepts, or examples provided by Ross Cameron.\n",
    "\n",
    "        Here is the cleaned transcription to use:\n",
    "        '\n",
    "        {transcription}\n",
    "        '\n",
    "        \"\"\"\n",
    "\n",
    "    client = openai.OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-2025-04-14\", #\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=min(count_tokens(transcription), 32768)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ],
   "id": "bf3d1eac49631b1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_path = \"D:/trading/Warrior Trading/Warrior Trading Courses/\"\n",
    "textes = glob.glob(base_path + \"**/*.txt\", recursive=True)\n",
    "textes = [f for f in textes if not os.path.basename(f).endswith(\"_summary.txt\")]\n",
    "# Remove existing summary files from the list\n",
    "print(f\"Found {len(textes)} files\")\n",
    "textes = [file for file in textes if not os.path.exists(file.replace(\".txt\", \"_summary.txt\"))]\n",
    "print(f\"Found {len(textes)} files to process\")\n",
    "textes"
   ],
   "id": "7533922ed3050182",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pbar = tqdm(textes)\n",
    "for file in pbar:\n",
    "    pbar.set_description(file)\n",
    "    # Check if the audio file already exists\n",
    "    if not os.path.exists(file.replace(\".txt\", \"_summary.txt\")):\n",
    "        # print the file size and the number of words\n",
    "        file_size = os.path.getsize(file)\n",
    "\n",
    "        transcription = \"\"\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            transcription = f.read()\n",
    "\n",
    "        # print the file size and the number of words\n",
    "        num_words = len(transcription.split())\n",
    "        print(f\"File size: {file_size} bytes\")\n",
    "        print(f\"Number of words: {num_words} words\")\n",
    "\n",
    "        summary = get_summary(transcription)\n",
    "        with open(file.replace(\".txt\", \"_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(summary)"
   ],
   "id": "8a95f474e7d9f4a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "322581e9e58272ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "aa35483e27f0c599",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
